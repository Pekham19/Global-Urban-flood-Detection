{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5cdfbf-97cb-4cd9-aae1-d968effa33b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PART A: TRAINING MODELS ===\n",
      "Sampling: Rain\n"
     ]
    }
   ],
   "source": [
    "# India_flood_testing - DEM extent authoritative, no AOI, urban-only LULC==13\n",
    "# Single-file Jupyter / Python script\n",
    "# Dependencies (run these once):\n",
    "# !pip install rasterio geopandas shapely fiona pyproj\n",
    "# !pip install scikit-learn xgboost joblib\n",
    "# !pip install pandas numpy matplotlib scipy\n",
    "\n",
    "import os, warnings, math, sys, time, zipfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio\n",
    "from rasterio import windows as rw\n",
    "from rasterio.enums import Resampling\n",
    "from rasterio.warp import reproject, Resampling as WarpResampling\n",
    "import joblib\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, RocCurveDisplay\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy import ndimage\n",
    "import geopandas as gpd\n",
    "from pyproj import Transformer\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ---------- small helper for OneHotEncoder ----------\n",
    "def make_onehot(handle_unknown=\"ignore\"):\n",
    "    try:\n",
    "        return OneHotEncoder(handle_unknown=handle_unknown, sparse_output=False)\n",
    "    except TypeError:\n",
    "        return OneHotEncoder(handle_unknown=handle_unknown, sparse=False)\n",
    "\n",
    "# ---------- USER EDITS ----------\n",
    "base_dir   = r\"C:\\Users\\DELL\\Desktop\\Cognitud\\Urban Flood\"\n",
    "output_dir = os.path.join(base_dir, \"outputs_cut_n30w120\")\n",
    "aligned_dir= os.path.join(base_dir, \"aligned_cut_n30w120\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "os.makedirs(aligned_dir, exist_ok=True)\n",
    "\n",
    "# Predictor rasters (edit to your files)\n",
    "factor_paths = {\n",
    "    \"Rain\":      os.path.join(base_dir, \"rainfall_intensity_ssp_1.tif\"),\n",
    "    \"Elevation\": os.path.join(base_dir, \"cut_n30w120.tif\"),  # DEM (authoritative)\n",
    "    \"Landcover\": os.path.join(base_dir, \"global_SSP1_RCP26_2030.tif\")\n",
    "}\n",
    "categorical_factors = [\"Landcover\"]\n",
    "\n",
    "# Training CSV points\n",
    "points_csv = os.path.join(base_dir, \"nonflood_points_no_buffer.csv\")\n",
    "LAT_COL = \"LATITUDE\"\n",
    "LON_COL = \"LONGITUDE\"\n",
    "LABEL_COL_PREFERRED = \"id\"\n",
    "\n",
    "# Model files\n",
    "rf_model_path  = os.path.join(output_dir, \"rf_pipe.pkl\")\n",
    "xgb_model_path = os.path.join(output_dir, \"xgb_pipe.pkl\")\n",
    "\n",
    "# Tiling & memory knobs\n",
    "OVERLAP = 32\n",
    "ROWS_PER_CHUNK = 1024\n",
    "RANDOM_STATE = 42\n",
    "ALIGN_INPUTS_ONCE = True\n",
    "AUTO_SKIP_TRAIN_IF_MODELS_EXIST = True\n",
    "USE_GPU = False\n",
    "BLOCK_SIZE = 1024\n",
    "DO_HYPERPARAM_TUNE = False\n",
    "\n",
    "# GDAL/Rasterio runtime options\n",
    "rasterio_env = dict(GDAL_CACHEMAX=512, NUM_THREADS=\"ALL_CPUS\")\n",
    "\n",
    "# ---------- check inputs exist ----------\n",
    "for k, v in factor_paths.items():\n",
    "    if not os.path.exists(v):\n",
    "        raise FileNotFoundError(f\"Missing predictor: {v}\")\n",
    "if not os.path.exists(points_csv):\n",
    "    raise FileNotFoundError(f\"Missing training CSV: {points_csv}\")\n",
    "\n",
    "# ---------- helper: ensure DEM has CRS (assign EPSG:4326 if missing) ----------\n",
    "def ensure_crs_assigned(src_path, crs_str=\"EPSG:4326\", out_dir=None):\n",
    "    \"\"\"\n",
    "    If raster has no CRS, write a copy with the provided CRS and return the path to the file\n",
    "    If raster already has CRS, return original path.\n",
    "    \"\"\"\n",
    "    with rasterio.Env(**rasterio_env):\n",
    "        with rasterio.open(src_path) as src:\n",
    "            if src.crs is not None:\n",
    "                return src_path\n",
    "            # read full array and profile\n",
    "            data = src.read(1)\n",
    "            profile = src.profile.copy()\n",
    "            profile.update(crs=crs_str)\n",
    "\n",
    "    # prepare output path\n",
    "    basename = os.path.basename(src_path)\n",
    "    name, ext = os.path.splitext(basename)\n",
    "    out_name = f\"{name}_proj{ext}\"\n",
    "    if out_dir is None:\n",
    "        out_dir = os.path.dirname(src_path)\n",
    "    out_path = os.path.join(out_dir, out_name)\n",
    "\n",
    "    # write new file with assigned CRS\n",
    "    with rasterio.Env(**rasterio_env):\n",
    "        with rasterio.open(out_path, \"w\", **profile) as dst:\n",
    "            dst.write(data, 1)\n",
    "    print(f\"Assigned CRS {crs_str} to '{src_path}' -> wrote: {out_path}\")\n",
    "    return out_path\n",
    "\n",
    "# ---------- sampling & alignment helpers ----------\n",
    "def sample_points_from_raster(src_path, lons, lats, assumed_src_crs=\"EPSG:4326\"):\n",
    "    with rasterio.open(src_path) as src:\n",
    "        if src.crs is None:\n",
    "            xs, ys = lons, lats\n",
    "        elif src.crs.to_string() != \"EPSG:4326\":\n",
    "            tfm = Transformer.from_crs(\"EPSG:4326\", src.crs, always_xy=True)\n",
    "            xs, ys = tfm.transform(lons, lats)\n",
    "        else:\n",
    "            xs, ys = lons, lats\n",
    "        samples = list(src.sample(zip(xs, ys)))\n",
    "        arr = np.array([s[0] if len(s) else np.nan for s in samples], dtype=\"float32\")\n",
    "        if src.nodata is not None:\n",
    "            arr[arr == src.nodata] = np.nan\n",
    "        return arr\n",
    "\n",
    "def align_to_ref(src_path, ref_profile, resampling, dst_path, assumed_src_crs=\"EPSG:4326\"):\n",
    "    ref_crs = ref_profile[\"crs\"]\n",
    "    ref_transform = ref_profile[\"transform\"]\n",
    "    out_h, out_w = ref_profile[\"height\"], ref_profile[\"width\"]\n",
    "    with rasterio.Env(**rasterio_env):\n",
    "        with rasterio.open(src_path) as src:\n",
    "            src_arr = src.read(1).astype(np.float32)\n",
    "            if src.nodata is not None:\n",
    "                src_arr[src_arr == src.nodata] = np.nan\n",
    "            dst = np.full((out_h, out_w), np.float32(np.nan), dtype=np.float32)\n",
    "            reproject(\n",
    "                source=src_arr,\n",
    "                destination=dst,\n",
    "                src_transform=src.transform,\n",
    "                src_crs=src.crs or assumed_src_crs,\n",
    "                dst_transform=ref_transform,\n",
    "                dst_crs=ref_crs,\n",
    "                resampling=resampling,\n",
    "                src_nodata=np.nan,\n",
    "                dst_nodata=np.float32(np.nan),\n",
    "                init_dest_nodata=True,\n",
    "            )\n",
    "    prof = ref_profile.copy()\n",
    "    prof.update(count=1, dtype=\"float32\", nodata=np.float32(np.nan),\n",
    "                compress=\"lzw\", tiled=True, blockxsize=BLOCK_SIZE, blockysize=BLOCK_SIZE, predictor=2)\n",
    "    with rasterio.open(dst_path, \"w\", **prof) as dst_src:\n",
    "        dst_src.write(dst, 1)\n",
    "\n",
    "# small array utilities\n",
    "def expanded_window(win, max_w, max_h, overlap):\n",
    "    col0 = max(0, int(win.col_off) - overlap)\n",
    "    row0 = max(0, int(win.row_off) - overlap)\n",
    "    col1 = min(max_w, int(win.col_off + win.width) + overlap)\n",
    "    row1 = min(max_h, int(win.row_off + win.height) + overlap)\n",
    "    return rw.Window(col_off=col0, row_off=row0, width=col1 - col0, height=row1 - row0)\n",
    "\n",
    "\n",
    "def crop_array_to_window(arr, big_win, target_win):\n",
    "    r0 = int(target_win.row_off) - int(big_win.row_off)\n",
    "    c0 = int(target_win.col_off) - int(big_win.col_off)\n",
    "    r1 = r0 + int(target_win.height)\n",
    "    c1 = c0 + int(target_win.width)\n",
    "    return arr[r0:r1, c0:c1]\n",
    "\n",
    "\n",
    "def fill_nan_nearest(a):\n",
    "    if not np.isnan(a).any():\n",
    "        return a\n",
    "    mask = np.isnan(a)\n",
    "    _, inds = ndimage.distance_transform_edt(mask, return_indices=True)\n",
    "    filled = a[tuple(inds)]\n",
    "    return filled\n",
    "\n",
    "\n",
    "def predict_window(models, feat_dict, out_shape, feature_cols):\n",
    "    h, w = out_shape\n",
    "    n = h * w\n",
    "    flat_feats = [feat_dict[c].reshape(n) for c in feature_cols]\n",
    "    stacked = np.column_stack(flat_feats)\n",
    "    mask = np.all(~np.isnan(stacked), axis=1)\n",
    "    proba_mean = np.full(n, np.nan, dtype=np.float32)\n",
    "    chunk_size = ROWS_PER_CHUNK * w\n",
    "    for start in range(0, n, chunk_size):\n",
    "        end = min(n, start + chunk_size)\n",
    "        submask = mask[start:end]\n",
    "        if not np.any(submask):\n",
    "            continue\n",
    "        df = pd.DataFrame({col: stacked[start:end, i][submask] for i, col in enumerate(feature_cols)})\n",
    "        for c in categorical_factors:\n",
    "            if c in df.columns:\n",
    "                df[c] = df[c].astype(object)\n",
    "        probs = []\n",
    "        for pipe in models:\n",
    "            probs.append(pipe.predict_proba(df)[:, 1])\n",
    "        mean_probs = np.nanmean(np.vstack(probs), axis=0)\n",
    "        proba_mean[start:end][submask] = mean_probs\n",
    "    return proba_mean.reshape((h, w))\n",
    "\n",
    "# ---------- PART A: TRAINING ----------\n",
    "print(\"=== PART A: TRAINING MODELS ===\")\n",
    "feature_cols = list(factor_paths.keys())\n",
    "if \"Elevation\" not in factor_paths:\n",
    "    raise ValueError(\"You must provide 'Elevation' (DEM) in factor_paths to establish prediction extent/CRS.\")\n",
    "\n",
    "models_exist = os.path.exists(rf_model_path) and os.path.exists(xgb_model_path)\n",
    "if AUTO_SKIP_TRAIN_IF_MODELS_EXIST and models_exist:\n",
    "    print(\"Models found. Loading and skipping training.\")\n",
    "    rf_pipe  = joblib.load(rf_model_path)\n",
    "    xgb_pipe = joblib.load(xgb_model_path)\n",
    "else:\n",
    "    points = pd.read_csv(points_csv)\n",
    "    for col_needed in [LAT_COL, LON_COL]:\n",
    "        if col_needed not in points.columns:\n",
    "            raise ValueError(f\"CSV missing required column: {col_needed}\")\n",
    "    label_col = LABEL_COL_PREFERRED if LABEL_COL_PREFERRED in points.columns else \"id\"\n",
    "\n",
    "    lats   = points[LAT_COL].values\n",
    "    lons   = points[LON_COL].values\n",
    "    labels = points[label_col].astype(int).values\n",
    "\n",
    "    samples = {}\n",
    "    for name, path in factor_paths.items():\n",
    "        print(f\"Sampling: {name}\")\n",
    "        arr = sample_points_from_raster(path, lons, lats)\n",
    "        if name in categorical_factors:\n",
    "            arr_int = np.where(np.isnan(arr), np.nan, np.round(arr).astype(np.float32))\n",
    "            samples[name] = arr_int\n",
    "        else:\n",
    "            samples[name] = arr\n",
    "\n",
    "    df_train = pd.DataFrame(samples)\n",
    "    df_train[\"Label\"] = labels\n",
    "    X = df_train[feature_cols]\n",
    "    y = df_train[\"Label\"]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify=y, random_state=RANDOM_STATE)\n",
    "\n",
    "    num_cols = [c for c in feature_cols if c not in categorical_factors]\n",
    "    cat_cols = [c for c in feature_cols if c in categorical_factors]\n",
    "\n",
    "    num_pipe = Pipeline([(\"imputer\", KNNImputer(n_neighbors=5)), (\"scaler\", StandardScaler()),])\n",
    "    cat_pipe = Pipeline([(\"imputer\", SimpleImputer(strategy=\"most_frequent\")), (\"onehot\", make_onehot(handle_unknown=\"ignore\")),])\n",
    "    transformers = []\n",
    "    if num_cols: transformers.append((\"num\", num_pipe, num_cols))\n",
    "    if cat_cols: transformers.append((\"cat\", cat_pipe, cat_cols))\n",
    "    preprocessor = ColumnTransformer(transformers, remainder=\"drop\")\n",
    "\n",
    "    rf = RandomForestClassifier(n_estimators=400, max_depth=16, n_jobs=-1, class_weight=\"balanced_subsample\", random_state=RANDOM_STATE)\n",
    "    tree_method = \"gpu_hist\" if USE_GPU else \"hist\"\n",
    "    predictor = \"gpu_predictor\" if USE_GPU else None\n",
    "    xgbc = xgb.XGBClassifier(n_estimators=400, learning_rate=0.05, max_depth=8, subsample=0.8,\n",
    "                             colsample_bytree=0.6, objective=\"binary:logistic\",\n",
    "                             scale_pos_weight=max(1.0, (y_train == 0).sum() / max(1, (y_train == 1).sum())),\n",
    "                             tree_method=tree_method, predictor=predictor, random_state=RANDOM_STATE,\n",
    "                             use_label_encoder=False, eval_metric=\"logloss\",)\n",
    "\n",
    "    rf_pipe  = Pipeline([(\"pre\", preprocessor), (\"clf\", rf)])\n",
    "    xgb_pipe = Pipeline([(\"pre\", preprocessor), (\"clf\", xgbc)])\n",
    "\n",
    "    if DO_HYPERPARAM_TUNE:\n",
    "        rf_param = {\"clf__n_estimators\": [100, 200, 300], \"clf__max_depth\": [8, 12, 16], \"clf__max_features\": [\"sqrt\", 0.5, None],}\n",
    "        xgb_param = {\"clf__n_estimators\": [200, 400], \"clf__max_depth\": [4, 6, 8], \"clf__learning_rate\": [0.01, 0.05, 0.1], \"clf__subsample\": [0.6, 0.8, 1.0],}\n",
    "        rf_search = RandomizedSearchCV(rf_pipe, rf_param, n_iter=6, scoring=\"roc_auc\", n_jobs=-1, cv=3, random_state=RANDOM_STATE)\n",
    "        xgb_search = RandomizedSearchCV(xgb_pipe, xgb_param, n_iter=6, scoring=\"roc_auc\", n_jobs=-1, cv=3, random_state=RANDOM_STATE)\n",
    "        rf_search.fit(X_train, y_train)\n",
    "        xgb_search.fit(X_train, y_train)\n",
    "        rf_pipe = rf_search.best_estimator_\n",
    "        xgb_pipe = xgb_search.best_estimator_\n",
    "    else:\n",
    "        for c in cat_cols:\n",
    "            X_train[c] = X_train[c].astype(object)\n",
    "            X_test[c]  = X_test[c].astype(object)\n",
    "        rf_pipe.fit(X_train, y_train)\n",
    "        xgb_pipe.fit(X_train, y_train)\n",
    "\n",
    "    # Quick eval & save\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    for name, pipe in {\"RF\": rf_pipe, \"XGB\": xgb_pipe}.items():\n",
    "        y_pred  = pipe.predict(X_test)\n",
    "        y_proba = pipe.predict_proba(X_test)[:, 1]\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        auc = roc_auc_score(y_test, y_proba)\n",
    "        print(f\"\\n{name} | Accuracy={acc:.3f}, AUC={auc:.3f}\")\n",
    "        print(confusion_matrix(y_test, y_pred))\n",
    "        print(classification_report(y_test, y_pred, digits=3))\n",
    "        RocCurveDisplay.from_predictions(y_test, y_proba, name=name)\n",
    "    plt.title(\"ROC Curves — RF vs XGB\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, \"roc_rf_xgb.png\"), dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "    joblib.dump(rf_pipe,  rf_model_path,  compress=3)\n",
    "    joblib.dump(xgb_pipe, xgb_model_path, compress=3)\n",
    "    print(\"Models saved:\", rf_model_path, xgb_model_path)\n",
    "\n",
    "# ---------- PART B: ALIGN INPUTS (DEM reference) ----------\n",
    "print(\"\\n=== PART B: ALIGNING INPUTS TO DEM ===\")\n",
    "\n",
    "# Ensure DEM has CRS assigned (assign WGS84 if missing)\n",
    "dem_path = factor_paths[\"Elevation\"]\n",
    "dem_path = ensure_crs_assigned(dem_path, crs_str=\"EPSG:4326\", out_dir=aligned_dir)\n",
    "# if a new file was written, update factor_paths reference for elevation\n",
    "factor_paths[\"Elevation\"] = dem_path\n",
    "\n",
    "with rasterio.open(dem_path) as dem_ds:\n",
    "    ref_profile = dem_ds.profile.copy()\n",
    "    ref_crs = dem_ds.crs\n",
    "    ref_transform = dem_ds.transform\n",
    "    dem_width, dem_height = dem_ds.width, dem_ds.height\n",
    "    dem_bounds = dem_ds.bounds\n",
    "    print(\"DEM CRS:\", ref_crs, \"size:\", dem_width, dem_height)\n",
    "    print(\"DEM bounds:\", dem_bounds)\n",
    "\n",
    "if ALIGN_INPUTS_ONCE:\n",
    "    for name in list(factor_paths.keys()):\n",
    "        src = factor_paths[name]\n",
    "        dst = os.path.join(aligned_dir, f\"{name}.tif\")\n",
    "        if not os.path.exists(dst):\n",
    "            resamp = WarpResampling.nearest if name in categorical_factors else WarpResampling.bilinear\n",
    "            print(f\"Aligning {name} -> {dst}  (resampling: {'nearest' if name in categorical_factors else 'bilinear'})\")\n",
    "            align_to_ref(src, ref_profile, resamp, dst, assumed_src_crs=\"EPSG:4326\")\n",
    "        factor_paths[name] = dst\n",
    "\n",
    "# ---------- PART C: STREAMED PREDICTION (full DEM extent, URBAN-only where LULC == 6) ----------\n",
    "print(\"\\n=== PART C: STREAMED PREDICTION (DEM extent, URBAN only LULC==13) ===\")\n",
    "rf_pipe = joblib.load(rf_model_path)\n",
    "xgb_pipe = joblib.load(xgb_model_path)\n",
    "models = [rf_pipe, xgb_pipe]\n",
    "\n",
    "final_profile = ref_profile.copy()\n",
    "final_profile.update(driver=\"GTiff\", dtype=\"float32\", count=1, nodata=np.float32(np.nan),\n",
    "                     compress=\"lzw\", BIGTIFF=\"YES\", tiled=True, blockxsize=BLOCK_SIZE, blockysize=BLOCK_SIZE, predictor=2)\n",
    "final_map = os.path.join(output_dir, \"UB_Flood_cut_n30w120.tif\")  # change the final output name --------------------------------------------->\n",
    "\n",
    "URBAN_VALUE = 6  # Landcover value indicating urban\n",
    "\n",
    "with rasterio.Env(**rasterio_env):\n",
    "    with rasterio.open(factor_paths[\"Elevation\"]) as ref_ds, rasterio.open(final_map, \"w\", **final_profile) as out_ds:\n",
    "        width, height = ref_ds.width, ref_ds.height\n",
    "\n",
    "        # open aligned predictors (these are the aligned files in aligned_dir)\n",
    "        predictors = {name: rasterio.open(path) for name, path in factor_paths.items()}\n",
    "        feature_cols = list(predictors.keys())\n",
    "\n",
    "        total_tiles = math.ceil(height / BLOCK_SIZE) * math.ceil(width / BLOCK_SIZE)\n",
    "        processed = 0\n",
    "        t0 = time.time()\n",
    "\n",
    "        for r_off in range(0, height, BLOCK_SIZE):\n",
    "            h = min(BLOCK_SIZE, height - r_off)\n",
    "            for c_off in range(0, width, BLOCK_SIZE):\n",
    "                w = min(BLOCK_SIZE, width - c_off)\n",
    "                tile_win = rw.Window(col_off=c_off, row_off=r_off, width=w, height=h)\n",
    "\n",
    "                big_win = expanded_window(tile_win, width, height, OVERLAP)\n",
    "\n",
    "                feat_dict = {}\n",
    "                all_nan = True\n",
    "                urban_mask = np.zeros((h, w), dtype=bool)\n",
    "\n",
    "                # Read each predictor. For Landcover we keep a raw copy (no nearest fill)\n",
    "                for name, src in predictors.items():\n",
    "                    arr_big = src.read(1, window=big_win).astype(np.float32)\n",
    "                    if src.nodata is not None:\n",
    "                        arr_big[arr_big == src.nodata] = np.nan\n",
    "                    tile_arr = crop_array_to_window(arr_big, big_win, tile_win)\n",
    "\n",
    "                    if name == \"Landcover\":\n",
    "                        # Keep a raw copy to determine urban mask (do NOT fill)\n",
    "                        tile_arr_raw = tile_arr.copy()\n",
    "                        # compute urban mask — compare with tolerance in case of float storage\n",
    "                        # round before comparison if values should be integers\n",
    "                        with np.errstate(invalid=\"ignore\"):\n",
    "                            urban_mask = np.isfinite(tile_arr_raw) & (np.round(tile_arr_raw) == URBAN_VALUE)\n",
    "\n",
    "                        # For model features, fill missing values so ML pipeline can run\n",
    "                        tile_arr_filled = fill_nan_nearest(tile_arr)\n",
    "                        feat_dict[name] = tile_arr_filled\n",
    "                        if all_nan and np.any(~np.isnan(tile_arr_filled)):\n",
    "                            all_nan = False\n",
    "                    else:\n",
    "                        # For numeric predictors fill NaNs so the model has inputs\n",
    "                        tile_arr_filled = tile_arr\n",
    "                        # if entirely NaN, attempt nearest fill (keeps continuity across tiles)\n",
    "                        tile_arr_filled = fill_nan_nearest(tile_arr_filled)\n",
    "                        feat_dict[name] = tile_arr_filled\n",
    "                        if all_nan and np.any(~np.isnan(tile_arr_filled)):\n",
    "                            all_nan = False\n",
    "\n",
    "                # If there are no urban pixels in this tile, skip predicting and write NaNs\n",
    "                if not urban_mask.any() or all_nan:\n",
    "                    out_ds.write(np.full((h, w), np.float32(np.nan)), 1, window=tile_win)\n",
    "                else:\n",
    "                    # predict (this returns probabilities for entire tile)\n",
    "                    proba = predict_window(models, feat_dict, (h, w), feature_cols).astype(np.float32)\n",
    "\n",
    "                    # Ensure predictions only kept inside urban mask\n",
    "                    proba[~urban_mask] = np.nan\n",
    "\n",
    "                    # Also ensure any places with invalid features are NaN\n",
    "                    out_ds.write(proba, 1, window=tile_win)\n",
    "\n",
    "                processed += 1\n",
    "                if processed % 200 == 0 or processed == total_tiles:\n",
    "                    pct = 100.0 * processed / max(1, total_tiles)\n",
    "                    elapsed = (time.time() - t0) / 60.0\n",
    "                    print(f\"\\rProcessed {processed}/{total_tiles} tiles ({pct:.1f}%) in {elapsed:.1f} min\", end=\"\")\n",
    "\n",
    "        print(\"\\nAll tiles processed.\")\n",
    "        for src in predictors.values():\n",
    "            src.close()\n",
    "\n",
    "print(\"\\n✅ Final urban-only map saved:\", final_map)\n",
    "\n",
    "# ---------- Quicklook (urban-only) ----------\n",
    "print(\"\\nSaving quicklook PNG (urban-only)...\")\n",
    "with rasterio.open(final_map) as ds:\n",
    "    out_h = max(1, ds.height // 8)\n",
    "    out_w = max(1, ds.width  // 8)\n",
    "    small = ds.read(1, out_shape=(out_h, out_w), resampling=Resampling.average)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.imshow(small, cmap=\"viridis\")\n",
    "plt.colorbar(label=\"Susceptibility (0-1)\")\n",
    "plt.title(\"Ensemble Susceptibility (URBAN only, LULC==13)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, \"flood_quicklook_urban_only.png\"), dpi=150)\n",
    "plt.close()\n",
    "plt.show()\n",
    "print(\"Quicklook saved to\", os.path.join(output_dir, \"flood_quicklook_urban_only.png\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9da36c6-a958-470d-9076-f516a8f1ab2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
